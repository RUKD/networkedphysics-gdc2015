
   + Introduction:

     - this talk is about how to synchronize a simulation running on one computer so it can be viewed on another

     - there are three techniques to do this:

          1. deterministic lockstep
          2. snapshot interpolation
          3. state synchronization

     - In this talk we will work through how to network a test simulation using each of these techniques

     - we're also going to do a take a quick break in the middle for a bandwidth optimization case study,
       working through all the tricks and techniques required to optimize the snapshot interpolation bandwidth
       down to a reasonable amount.

     - finally: what this talk is not about: latency hiding, choice of network topology: 
       should I use client/server or peer-to-peer? anti-cheat techniques for networked physcis.

     - these topics are all very complicated and worthy of a talk of their own!

   + The Physics Simulation:

     - lets take a look at the simulation we're going to network

     - video: single cube (rigid body simulation, cube is rolling/tumbling due to friction, a bit unpredictable, this is intentional)

     - video: cube rolling about on other cubes (interacting with other objects, all objects are gameplay affecting, eg. push back on the player)

     - video: blowing cubes around (I wanted a way for the player to affect lots of other objects in the world, description of implementation with spring hooke's law, plus force pushing players out)

     - video: katamari (a big ball of constraints, every object in the ball is still simulated, basically every cube within a radius has force applied towards player cube center. very hard case to network because all objects in the katamari ball affect the motion of the player and each other!)

   + Deterministic Lockstep:

     - diagram to talk over: basic idea, start from teh same initial state, apply the same inputs = exactly the same result. determinsm.

     - video: non-determinism

     - video: determinism -- (ODE has a random number in the solver, setting its seed to the frame number before running the simulation fixes the non-determinism)

     - floating point determinism discussion. this is hard stuff. difficulties, gotchas etc. link to article for more information.

     - video: send inputs over TCP. 1% packet loss, 100ms.

     - video: send inputs over TCP. 2% packet loss, 200ms.

     - video: send inputs over TCP. 5% packet loss, 250ms.

     - video: send inputs over UDP. 25% packet loss, 250ms. ---> perfect. How?

     - change the rules. implement the reliability differently!

     - diagram: input structure. it's just 6 bits.

     - diagram: showing input packets sequence/num_inputs/inputs

     - diagram: showing delta encoding, one bit not changed.

     - diagram showing bandwidth, worst case, best case etc. brag a bit. it's really low bandwidth. fuck TCP.

   + Snapshot Interpolation

     - lets take a totally different approach. don't run the simulation on the right side at all

     - video: send the snapshots across 60 times per-second => jitter. what's happening? packets don't arrive nicely spaced out over the internet, eg. 1/60th of a second apart. they arrive jittered (time variance of packet delivery).

     - video: snapshots at 10 packets per-second. strobing. it's working. much less bandwidth (6X less.)

     - video: linear interpolation. some artifacts.

     - video: hermite interpolation for position. need to send linear velocity now. slerp is good enough for orientation (nlerp was not)

     - diagram: how the interpolation buffer works

     - how to handle packet loss? snapshots are sent over UDP what if a snapshot doesn't get through?

     - diagram: handling packet loss by adding latency. enough to drop two packets in a row +/2 frame of latency @ 60fps = 350ms.

     - if we could increase the send rate we could reduce this latency. for example if the send rate is 60 packets per-second,
       we get the same packet loss and jitter protection with a delay of only 85ms.

   + Bandwidth Optimization (Case Study)

     - video: snapshots at 60 packets-per-second. it's really huge - 18mbit/sec.

     - diagram + math: show the calculations that lead up to 18megabits/sec. we have a lot of work to do!

     - diagram: struct or table showing per-cube snapshot data, show # of bits each, total bits.

     - math/text: don't just 8.8.8.8. you get a better result with smallest three. derive properties. 

     - diagram: compression amount in bits vs. original: 2 + 9 + 9 + 9 = 29 bits (vs. 128 bits!!!)

     - diagram: bound and quantize linear velocity (+/- range in meters per-second, low precision per-meter, end result bits)

     - diagram: at rest bit. diagram showing encoding of bits for at rest and how it works.

     - video: at rest bits. bandwidth is much improved but now gets higher when player moves around.

     - diagram: why send linear velocity at all? linear interpolation is good enough at high send rate. you need hermite only at lower send rates (10pps, maybe 20pps). cross off linear velocity from the bits sent entirely and calculate total bits per-cube.

     - diagram: bound and quantize position (+/- range, precision per-meter, end result bits)

     - diagram: show end result per-cube state in bits (x% of uncompressed size)

     - video: end result absolute compression. steady state Xmbit/sec.

     - as far as we can go with absolute compression. any further reduction in accuracy results in visual glitches.

     - we still need an order of magnitude better compression...

     - delta compression. idea: encode relative to a previously sent snapshot

     - diagram: snapshot sequences, acks. only care about the most recently received snapshot so single ack sequence is fine.

     - diagram: buffering snapshots on both send (for encode) and receive (for decode). only need a few seconds worth, eg. up to your timeout value perhaps.

     - diagram: if a cube isn't different to the baseline sequence, write one bit on send. on receive if that bit is true, just copy across the cube data from the baseline snapshot, otherwise serialize the cube update using the compression techniques already developed.

     - video: demonstration. big order of magnitude win! small gains from here on out. we're going to have to work hard to lower the bandwidth while lots of cubes are moving. lots of small gains add up.

     - diagram: packet structure with lots of skip bits. can we do better? 

     - diagram: yes. skip each index costs 10 bits, so if less than 90 objects are different from the baseline, we can encode them more efficiently by just specifying the *index* of each changed cube state. we can encode this choice in the header, and pick the most efficient encoding depending on the # of changed cubes.

     - diagram: packet structure with header, and skip bits if > 90 objects changed, other wise num cubes, index, state data etc.

     - diagram: can we do even better? yes. encode index relative to previous changed cube index. on average with the right encoding can get 5.5 bits

     - diagram: statistically analyzed the set of relative changed indices in snapshots for typical movement. result was the following encoding:
       (diagram showing encoding)

     - diagram: updated packet structure, choice between skip bits and relative now more complicated. actually run through a fake encoding with the set of changed cubes and measure how many bits with relative. if it's less than 900, use it, otherwise fall back to skip bits.

     - video: result of skip bits. looking decent. peaking at 400kbps. lower than before. also, lower steady state when only few cubes are changing (bascially all packet header @ 60pps)

     - diagram: lets encode position relative to previous position, eg. a position offset. what's the best encoding?

     - data set: I dumped out the typical positions and base positions one-per-line and analyized with a greedy search.

     - diagram: best result was a two level encoding 5-9 per-component, one bit falling back to absolute if position offset is too far from base. brag, show the per-component size is just 7.5 bits per-position component on average. crazy!!!

     - relative orientation. tried different techniques, axis-angle (4 vector), combined axis-angle (3 vector), relative quaternion (multiply by conjugate).

     - best result obtained: relative quaternion assuming w is largest component, saves two bits right there, dual encoding.

     - however, for simplicity, since 

     - video: end result. basically 256kbit/sec.

     - can you go better? sure. reduce to 20 packets per-second now it's trivially small, but extra delay again.

     - why not, delta encode three snapshots next to each other redundantly per-packet, sent 20 times per-second. best trade-off between bandwidth/and latency I believe.

   + State Synchronization

     - ...

   + Conclusion

     - deterministic lockstep: pros and cons
     - snapshot interpolation: pros and cons
     - state synchornization: pros and cons

     - how to choose the correct one for your situation

     - what's the best one long term? bandwidth is going up, probably unbounded, latency has a hard limit (speed of light)
       therefore, I think snapshot interpolation is the most robust, simplest technique and is also the most reliable.
