DONE:

TODO:

    Why is serialize read slower than serialize write?

    ----------------------

    Add some macros to make defining serialization and messages easier.

    ----------------------

    Make sure all connection packets are deleted after "ReadPacket"

    ----------------------

    Pass over todos and make notes of what else needs to be done.

    ----------------------

    DNSResolver is probably completely broken. Get it working and break
    down tasks that would turn it into something that can be *pre-allocated*
    and doesn't do allocations at runtime.

    ----------------------

    All class configs should be *const*.

    ----------------------

    Need to disallow copy construction for classes with pointers.

    ----------------------

    Basic logging. Just start with a "Log" macro that can be redirected
    to a "Logger" interface via virtual fn. 

    Of course, this is disabled in release build (NDEBUG) but it is 
    the easiest way to make sure the library can output logs to the
    appropriate place (console, TTY, file, whatever...)

    Should logs include the "\n" at the end?

    It would be nice if they didn't have to. It's easy to forget.

    ----------------------











    --------------------

    Consolidate bitpacker into stream.

    --------------------

    It appears that fragment allocation inside GetData and ProcessData
    is expensive. Instead, the fragment should work on a pointer direct
    to the area of data to be serialized to/from, so there is no alloc 
    and copy.

    This is probably the largest optimization that can be made at this stage.

    ^-------- PROFILE AGAIN BEFORE TRYING THIS!!!

    --------------------

    I need a way to determine the speed of the code so that one run
    to the next is faster. Right now I'm chopping off bits of code
    that shouldn't be slow, and then they go away from the profile
    but eventually, I'm going to be looking for an overall speed
    improvement, average milliseconds per-100 updates or something
    like this that can be compared between runs.

    --------------------

    Optimization for fragments, track oldest unacked fragment id, and start there
    and go left to right to search for fragments to send.

    --------------------

    Add a new fragmentSendWindow config, eg. 64 and only look this far past
    the oldest unacked fragment. Should save unnecessary scans for large block
    sizes.

    --------------------

    Could save a bit of memory and maybe gain some speed by switching 
    the received fragment data to a bitfield

    We only need one bit per-fragment, "has it been received?"

    --------------------






    ------------------------

    Add code on server to send server data block to client.

    Block must be *constant*. eg. add it as part of server config

    Server sends one block fragment per-packet. No need for complicated reliability.

    Client replies with a separate packet acking each fragment he sees. Nothing complicated.

    Server just keeps sending them until all acked.

    Once server has acks for every fragment, go into the requesting client block state.

    Client should store, and make the server data block accessible via accessor.

    Add unit test to verify it's working, make sure to check the block size and contents match.

    ------------------------

    Some thing in reverse for client -> server block.

    Once the block transfers have completed, go to connected state.

    Make client block accessible per-server, and make sure it is cleared when the client disconnects.

    Add test to verify server receives the correct size block and contents from the client.

    ------------------------

    Implement fragmentation and reassembly for large packets, do this
    at the connection level once we have large snapshots, this would
    probably be a good idea to have -- set MTU to 1200 bytes.

    Keep it simple. A packet is received when all its fragments
    have been received. If any of the fragments are dropped,
    then the packet is dropped.

    I propose a simple header, eg. a packet type for fragment packet
    with a header x/y fragments and the sequence number of the *unacked*
    packet.

    Then the complexity becomes:

    a) writing the fragments, and not sending them out too rapidly
    b) on the receive side collating the fragments and reassembling them.

    ------------------------






    *** SEND TABLES ***

    ---------------

    Implement send table concept. Implement delta encoding tables etc.

    Use the server data to communicate this table down to the client.

    ------------------------

    Actually implement a client/server setup and host the server in the cloud.

    Provide build steps using chef/knife or whatever to easily deploy this server.

    ------------------------









WOULD BE NICE:

    ----------------

    Idea for logging, have an enum of channels, and per-channel a level integer
    Initial level is zero. Enable logging by setting the level. Per-channel logs
    can be emitted by passing the level, which defaults to 1.

    Log( "hello everybody %d\n", value );

    On a per-file basis, specify the current log channel via #define

    This may require the project gets split up into cpp files first.

    ----------------

    For the message and block allocator, I'm thinking of a thread
    local storage allocator that detects when the thread that is
    calling it is *not* the same as the thread that it is running
    on, and in this case adds the deallocs to a list (atomic) which 
    is processed inside the allocator update.

    Alternatively, received messages could just have a policy
    that they will be deleted on the next update. Don't hold
    on to them.

    Same for blocks, potentially.

    ----------------

    Add counters for all the different things inside the large blocks,
    eg. # of large blocks sent, received, read/written, also # of
    fragments read/written.

    Write some basic tests to verify these counters are functional.

    ------------------

    Might be nice to add a validate step to the config for connection/channels
    because it's possible to specify a config that doesn't work now. eg. 
    interdependent parameters.

    Would be nice if the reliable message channel could report the minimal functional
    budget that would work for it, given its configuration. This would be great
    for the connection to budget for the channel.

    This should be in the base class for channel interface, so we can generically
    work with and budget channels decently without knowing exactly what they are.

    ----------------------

    Move the channel budget out of the channel config (static)
    and in to the connection. 

    Channel budget should be dynamic. The user should be able to derive their own 
    connection type and specify channel budgets dynamically based on flow control, 
    for example.

    ---------------------

    Integrate the oodle library. Provide an #if USE_OODLE 1 type thing and hook it up
    for compression. Try it out in the stress test and see how it generates dictionaries
    and how much compression it gets post-dictionary and so on. Do not check in the oodle
    libs, but do check in the interface and source code that uses it.

    ---------------------

    Implement packet encryption via key, plus hash to detect tampering (unified). Optional feature.

    ---------------------

    Implement an unreliable channel (messages), 
    eg. queue up unreliable messages to send and discard any that don't fit in the packet.
    Bonus: Provide an optional functor to sort the unreliable messages in order of importance.

    --------------------

    Implement an atomic queue on top of the client and server interface for sending
    and receiving user packets. This interface should allow running the actual serialization
    and packet reading entirely on a separate thread. Do it here where it is most natural,
    to avoid overcomplicating the interface/connection code.

    ----------------
