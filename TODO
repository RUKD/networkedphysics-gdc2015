DONE:

TODO:

    -------------------------

    Put the context array void*[MaxContexts] inside the client and server.

    Clear all contexts to nullptr initially, and set the const void** on 
    the network interface as soon as the network interface is created.

    Provide accessors to set/get context by index up to max contexts
    on the client/server. Note that the context is *always* shared
    across all clients connected to a server. Same context!
    
    -------------------------

    Can't use context to discard connection packets on the server because
    context is the same for server, not per-client.

    What I really need is a callback fn that just discards a connection packet
    once it has serialized enough, eg. a "Validate" callback. If validate returns
    false then 

    But the validate callback itself needs the ptr to the clientl/server 
    object to perform the validation...

    So now we are back to context.

    So maybe the client/server context passed in to 0 is actually the context
    that is used for validation, and we can actually do this inside the connection
    packet serialize, eg. if the context 0 is non-null, cast, and iterate across
    looking for matching casts

    At this point we probably need a concept of maximum clients per-server
    for the data structure.

    I suggest 64 at this point.

    We need to verify that the config maxclients <= MaxClientsPerServer const.

    -------------------------

    Seems that both client and server should have a client server context object.

    That this object should be int numClients, address, per-client, client and server guid.

    This struct should provide quick find client by address, guid lookup.

    It is basically a hot-cold split, and something we would want anyway.

    Don't do a callback, just let the connection packet inspect this client/server
    context and do its work. I think there would need to be exclusion potentially
    while accessing this client/server context but it should be changed very
    infrequently on the client/server side (connecting clients) and on the serialize
    side it would only ever be read only.

    -------------------------

    Move the client/server guids back into the connection packet.

    If no matching connection is established, discard the connection packet (how?)

    Make sure all unit tests and soaks still pass.

    -------------------------

    In situations where measure streams are used, channels need a way
    to construct a stream with the appropriate contexts set on it.

    How can this be done?

    Seems like channels need access to a function that returns the 
    appropriate const void ** context pointer to set on the measure stream.

    -------------------------

    Might be a good idea to put the client/server context in the last
    slot, so the user can set slot 0. otherwise going to be annoying
    explaining to users why they have to start with slot 1 or higher.

    -------------------------

    In unit tests, add some sort of context message, eg. a message
    that would only function if a context is properly set on the 
    client/server.

    Subclass client/server for tests, and in the subclass implement
    something like OnConnected, OnDisconnected or whatever, such that
    context is setup on both client/server.

    -------------------------

    Implement something for the client/server test where the first
    256 bytes of the client/server data is reserved for a context
    struct.

    Subclass the client/server and set the context to the server
    data once connection is established (on both client/server),
    as well as clear the context when disconnected.

    Make sure that the test context message cannot serialize
    without having this context available. Just simple min/max
    for quantities in the test context message.

    Randomize the min/max context for each server, such that they
    are wildly different for each server, and completely incompatible
    eg. serialization will fail/assert if desynced.

    Verify that the soak client/server is able to function with
    repeated connect/disconnect and exchange of server data driving
    the context needed for test context messages.

    -------------------------









    ^------------ AT THIS POINT READY FOR SEND TABLES











    ------------------------

    Integrate LZ compressor for compressing large blocks, and for compressing
    initial block sent down to client.

    Ideally, LZ4 could be something enabled via config that is used, if it exists
    this way it is up to the user of the library to ensure they have LZ4 installed.

    I don't want to manage the LZ4 library includes/libs inside my library,
    if I can avoid it.

    It might be a good idea to see if LZ4 can compress typical packets sent as well,
    for example, put a bit in the header indicating that the packet is compressed,
    if LZ4 is enabled, and then decode the packet via LZ4.

    This would have to live at the network interface level, presumably.

    Potentially set a minimum packet size or block size for LZ compression,
    and even then, check if the compressed packet/block is larger than uncompressed
    and send uncompressed instead.

    Per-packet or block (large block), we would need a bit indicating if compressed.

    ------------------------

    Implement fragmentation and reassembly for large packets, do this
    at the connection level once we have large snapshots, this would
    probably be a good idea to have -- set MTU to 1200 bytes.

    Keep it simple. A packet is received when all its fragments
    have been received. If any of the fragments are dropped,
    then the packet is dropped.

    I propose a simple header, eg. a packet type for fragment packet
    with a header x/y fragments and the sequence number of the *unacked*
    packet.

    Then the complexity becomes:

    a) writing the fragments, and not sending them out too rapidly
    b) on the receive side collating the fragments and reassembling them.

    ------------------------

    Where does fragmentation and reassembly live?

    Ideally, I would like for it to be in the connection layer
    or at least somewhere that it doesn't need to be implemented
    from scratch with each different network interface implementation.

    Is this possible?

    Maybe it should just be at the interface level.

    ------------------------





    ------------------------

    Actually implement a client/server setup and host the server in the cloud.

    Provide build steps using chef/knife or whatever to easily deploy this server.

    How any server instances can I have per-core?

    ------------------------






    *** SEND TABLES ***

    ---------------

    Implement send table concept. Implement delta encoding tables etc.

    Use the server data to communicate this table down to the client.

    ---------------