DONE:

TODO:

    ------------------

    Could a more cache efficient data structure make this
    a faster? Almost certainly. For example, if CanSendMessage
    is slow, then perhaps its walking a lot of memory to query
    a single bool, and having that as a bit array (hot-cold split)
    could be a good idea.

    See if a hot cold split for the sliding window makes perf issues go away.

    I'm thinking a 32bit sequence + flags header, separate from the actual
    data which is in a different struct. Seems like a good idea!!!

    ------------------




    ------------------

    My suspicion is that the GetData is actually walking across
    almost the entirety of the fragment data structure on each
    write looking for fragments to send, and oldest fragment
    and that this is the primary cost right now.

    If I fix this it should normalize so the serialize read/write
    are the most expensive again.

    ------------------

    Things that would have the most impact on the profiler:

    1. Rework the allocation and free of "fragments"
       so they go through the scratch allocator instead. (DONE)

    2. Remove the std::vector usage inside the reliable channel 
       sliding windows and use scratch allocator instead (DONE)

*** 2.5. Don't be stupid about how iteration across fragments is performed. ***

    3. Convert the actual messages themselves to be allocated 
       via specific message allocator passed in to config
       (initially make this the scratch...)

    4. Move the block itself to be a raw pointer instead of a vector.
       Should we have a standardized block allocator? standard message
       allocator, or should this be a config thing? Can a block message
       take the block allocator pointer with it? Sure...

    ------------------

    I really need to create a pool allocator, then use this for the blocks

    This way I can completely remove the malloc/free from the profile SoakTest
    and verify that everything is actually working correctly.

    ------------------

    TestBSDSockets.cpp is broken again now that I'm properly deleting packets!

    ------------------

    Replace all STL usage with bitsquid containers.

    Remove STL header includes.

    Use the bitsquid allocators to track down memory leaks, eg.
    make sure each individual unit test checks for leaks.

    --------------------








    --------------------

    Optimization for fragments, track oldest unacked fragment id, and start there
    and go left to right to search for fragments to send.

    --------------------

    Add a new fragmentSendWindow config, eg. 64 and only look this far past
    the oldest unacked fragment. Should save unnecessary scans for large block
    sizes.

    --------------------

    Could save a bit of memory and maybe gain some speed by switching 
    the received fragment data to a bitfield

    We only need one bit per-fragment, "has it been received?"

    --------------------














    ----------------------

    TestBSDSockets is broken. I think the sent packets are getting
    deleted before they can be compared with the received packets?

    ----------------------

    Add some macros to make defining serialization and messages easier.

    ----------------------

    Basic logging. Just start with a "Log" macro that can be redirected
    to a "Logger" interface via virtual fn. 

    Of course, this is disabled in release build (NDEBUG) but it is 
    the easiest way to make sure the library can output logs to the
    appropriate place (console, TTY, file, whatever...)

    Should logs include the "\n" at the end?

    It would be nice if they didn't have to. It's easy to forget.

    ----------------------















    ------------------------

    Add code on server to send server data block to client.

    Block must be *constant*. eg. add it as part of server config

    Server sends one block fragment per-packet. No need for complicated reliability.

    Client replies with a separate packet acking each fragment he sees. Nothing complicated.

    Server just keeps sending them until all acked.

    Once server has acks for every fragment, go into the requesting client block state.

    Client should store, and make the server data block accessible via accessor.

    Add unit test to verify it's working, make sure to check the block size and contents match.

    ------------------------

    Some thing in reverse for client -> server block.

    Once the block transfers have completed, go to connected state.

    Make client block accessible per-server, and make sure it is cleared when the client disconnects.

    Add test to verify server receives the correct size block and contents from the client.

    ------------------------

    Implement fragmentation and reassembly for large packets, do this
    at the connection level once we have large snapshots, this would
    probably be a good idea to have -- set MTU to 1200 bytes.

    Keep it simple. A packet is received when all its fragments
    have been received. If any of the fragments are dropped,
    then the packet is dropped.

    I propose a simple header, eg. a packet type for fragment packet
    with a header x/y fragments and the sequence number of the *unacked*
    packet.

    Then the complexity becomes:

    a) writing the fragments, and not sending them out too rapidly
    b) on the receive side collating the fragments and reassembling them.

    ------------------------






    *** SEND TABLES ***

    ---------------

    Implement send table concept. Implement delta encoding tables etc.

    Use the server data to communicate this table down to the client.

    ------------------------

    Actually implement a client/server setup and host the server in the cloud.

    Provide build steps using chef/knife or whatever to easily deploy this server.

    ------------------------









WOULD BE NICE:

    Might be a good idea to consolidate bitpacker into stream class.

    -----------------

    Removed the htonl and ntohl calls inside bitpacker.

    On windows these calls are apparently slow (call out to DLL)

    I need to provide my own efficient byteswap functions in common.h,
    eg. fast_ntonl, or just bswap if big endian in/out.

    ----------------

    Idea for logging, have an enum of channels, and per-channel a level integer
    Initial level is zero. Enable logging by setting the level. Per-channel logs
    can be emitted by passing the level, which defaults to 1.

    Log( "hello everybody %d\n", value );

    On a per-file basis, specify the current log channel via #define

    This may require the project gets split up into cpp files first.

    ----------------

    For the message and block allocator, I'm thinking of a thread
    local storage allocator that detects when the thread that is
    calling it is *not* the same as the thread that it is running
    on, and in this case adds the deallocs to a list (atomic) which 
    is processed inside the allocator update.

    Alternatively, received messages could just have a policy
    that they will be deleted on the next update. Don't hold
    on to them.

    Same for blocks, potentially.

    ----------------

    Add counters for all the different things inside the large blocks,
    eg. # of large blocks sent, received, read/written, also # of
    fragments read/written.

    Write some basic tests to verify these counters are functional.

    ------------------

    Might be nice to add a validate step to the config for connection/channels
    because it's possible to specify a config that doesn't work now. eg. 
    interdependent parameters.

    Would be nice if the reliable message channel could report the minimal functional
    budget that would work for it, given its configuration. This would be great
    for the connection to budget for the channel.

    This should be in the base class for channel interface, so we can generically
    work with and budget channels decently without knowing exactly what they are.

    ----------------------

    Move the channel budget out of the channel config (static)
    and in to the connection. 

    Channel budget should be dynamic. The user should be able to derive their own 
    connection type and specify channel budgets dynamically based on flow control, 
    for example.

    ---------------------

    Integrate the oodle library. Provide an #if USE_OODLE 1 type thing and hook it up
    for compression. Try it out in the stress test and see how it generates dictionaries
    and how much compression it gets post-dictionary and so on. Do not check in the oodle
    libs, but do check in the interface and source code that uses it.

    ---------------------

    Implement packet encryption via key, plus hash to detect tampering (unified). Optional feature.

    ---------------------

    Implement an unreliable channel (messages), 
    eg. queue up unreliable messages to send and discard any that don't fit in the packet.
    Bonus: Provide an optional functor to sort the unreliable messages in order of importance.

    --------------------

    Implement an atomic queue on top of the client and server interface for sending
    and receiving user packets. This interface should allow running the actual serialization
    and packet reading entirely on a separate thread. Do it here where it is most natural,
    to avoid overcomplicating the interface/connection code.

    ----------------
