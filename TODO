DONE:

    Implement the code that serializes the message types, and uses the 
    factory on the reading side to create the message by type, and then
    serializes the message.

    Does the message really need to include the id? Yep. It does.

    Was clobbering the message id to 0 inside serialize write.

TODO:

    Seems to be something wrong with serialization or test harness.

    Message coming in with "sequence" (inside TestMessage) that is
    the last message sent, but it is in receive queue as 0 (and message id 0). 
    Almost like the message ptr is being reused, or flipped incorrectly at 
    some point. 

    What is going on?!

    --------------
    
    Now implement code to measure events and determine if they can fit into packet.

    Should this measurement be done at the point of constructing the packet data? (probably)

    How to ensure that this measurement is done only once?

    Don't just append one stream to another, as it throws off the journal check.

    ------------------

    Next implement fragmentation and reassembly for large blocks.

    Important: Think about large packets with fragmentation
    If a large packet is coming up ahead, make sure previous
    non-fragmented packets before it have all been sent, eg.
    only commit to sending a large fragmented block once 
    the previous blocks have been sent.

    Next: After a fragmented block. Basically, assume the fragmented
    block will take a long time. There is probably not a lot of benefit
    sending blocks *after* the fragmented block in anticipation of the
    block being sent. Unless the fragmented block is small (eg. only
    a few fragments). If it is a large, large chunk -- then it's
    best to stop and wait for that chunk to finish serializing through
    in slices.

    Important: Slice size should be fixed, and basically be as much
    data as you can fit in the channel configuration. Don't send #
    of bytes with each slice. You know the size from config.

    At end, make sure not to trash extra data, but do send extra 0's
    in the packet, to avoid special cases.

    ---------------------

PROTOCOL AND SERVER:

    Cap'n Proto looks a bit overengineered (eg. second systems effect)

    MessagePack looks a bit smaller and tight to me, but probably less efficient
    over the wire and in terms of packing time.

    Are protocol buffers worth integrating?

    Google snappy looks like a nice candidate for message compression

    Is there a nice library for message encryption between servers over UDP?
    (eg. a shared secret is fine, server code is not distributed)

    Nettle library looks OK. Does google have a library that they use?

    On write:

        serialize write -> compress -> encrypt -> sign -> send

    On read:

        recv -> verify signature -> decrypt -> serialize read

    If I have my own reliable ordered block channel, I can then derive
    specific channels from that, eg. JSONChannel, CapnProtoChannel,
    MsgPackChannel, ThriftChannel and so on... should be easy to add
    additional libraries and try them out. Try them all! :D

OPTIMIZATION:

    Implement bit packer first.

    Next try to implement range encoder.

    Study range encoder. How does it work? Can the decryption be done in place as per bitpacker?

    Send and receive queues should be lockless threadsafe

    Separate send and receive threads for NetworkInterface

    Some ninja must be done to make it easy for the channels to work
    with serialization being done on a separate thread. Ouch?

    Investigate different methods for sending and receiving UDP packets,
    eg. completion ports on Win32, whatever method is fastest on linux etc.

    Run throughput tests with linux hosts. Test CPU usage etc.
