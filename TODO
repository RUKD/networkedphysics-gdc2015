DONE:

TODO:

    Implement sending connection request state, and actually start
    sending packets over the interface.

    Add the connection request packet type to ClientServerPackets.h

    Make sure the client generates a guid at the start of connect by address.

    This guid should be passed in to the server on connect request,
    and this guid is carried along from the client all the way to
    successful connect (to avoid mismatching client packets from
    a previous connect attempt...)

    -------------------------

    Decide on the reasons server can deny connect, eg. full etc.
    might want to stash this data somewhere so it can be debugged.

    Add a unit test to verify the timeout when the server does
    not reply with the expected connection response in time.

    -------------------------

    Implement the server side

    Add the server connection response packet as well, eg. enum with type
    of response, as well as data, eg. denied, allowed, etc.

    Add server side code to detect connection request, and transform that
    into a per-client connection state on the server side.

    Add a way to force the server to deny connections.

    Add a unit test to verify the client has the connection denied.

    -------------------------

    Add another test to verify that both the client and server
    go past the connection request and into the challenge state
    on both the client and server.

    ------------------------

    Implement a reservation system at this point which allows a group of
    n players to have a reservation on the server. Don't muddy the water
    with teams at this point.

    Extend the connection state machine to pass in a token.

    If you have a token, and no reservation exists for that token,
    deny the connection request.

    Make my reservation system flexible such that new connections
    can be attempted from a client, *while* retaining connection
    to a current server, eg. I'd like the reservation to try to
    move a group of players to a new server, but if it fails,
    for those players to remain connected to current server.

    ------------------------

    Actually implement a client/server setup and host the server in the cloud.

    Provide build steps using chef/knife or whatever to easily deploy this server.

    ------------------------

    Implement cube demo with this protocol library, but in a client/server manner.

    Use this cube demo for the meeting with rocket hall

    ------------------------



WOULD BE NICE:

    ----------------

    Add an "Align" method to stream.

    Pass in # of bits to align to in stream ctor and default it to 8.

    This would be useful for testing compression with Oodle.

    ----------------

    Add counters for all the different things inside the large blocks,
    eg. # of large blocks sent, received, read/written, also # of
    fragments read/written.

    Write some basic tests to verify these counters are functional.

    --------------------

    Try to clean up the error handling from "ProcessData".

    Want three options:

    a) data is ok, keep processing rest of channels (common case)
    b) discard packet (no ack), but keep processing remaining channel data.
    c) discard packet and stop immediately. data is bad. don't process remaining channels.

    Probably want an enum result to return from process data, eg. ProcessDataResult

    Make sure that counters distinguish between each case, and that serialize read failure
    which still throws an exception is not counted the same as a packet discard above.

    Clean up counter names, remove that bad "PacketReadFailures" counter
    and replace it with something that makes more sense.

    ----------------

    I'd like a logging system. It's annoying to have to comment out and re-enable
    logs as I debug things. Would be nice to be able to have logs like Deja.

    ------------------

    Might be nice to add a validate step to the config for connection/channels
    because it's possible to specify a config that doesn't work now. eg. 
    interdependent parameters.

    Would be nice if the reliable message channel could report the minimal functional
    budget that would work for it, given its configuration. This would be great
    for the connection to budget for the channel.

    This should be in the base class for channel interface, so we can generically
    work with and budget channels decently without knowing exactly what they are.

    ----------------------

    Move the channel budget out of the channel config (static)
    and in to the connection. 

    Channel budget should be dynamic. The user should be able to derive their own 
    connection type and specify channel budgets dynamically based on flow control, 
    for example.

    --------------------

    Implement unreliable message channel.

    Implement something where if you pass in -1 to the channel budget,
    it gives that last channel access to the remaining bits in the packet.

    This prequires that a channel accurately estimates the bits it is 
    using in the packet data, eg. via return perhaps?

    We should verify that the estimated bits are >= the actual serialized
    bits on write. I'm OK if it is not exact, although it can be made so.

    After this is working, get the soak test working such that it 
    has a second channel of unreliable events with -1 budget.

    Send so many unreliable events that the packet is almost always full.

    Verify soak tests works, unreliable events get through etc.

    --------------

    It would be nice to bring back templated serialize functions, and have specialized
    read, write and measure streams. I think the code generated would be much more
    amenable to optimization, however before doing this I should definitely profile.

    --------------------

    Instead of walking the send queue to find the oldest message id not acked,
    cache this value, and on each update, walk left to right to skip past acked
    messages in the send queue to get the new value.

    --------------------

    Optimization for fragments, track oldest unacked fragment id, and start there
    and go left to right to search for fragments to send.

    Add a new fragmentSendWindow config, eg. 64 and only look this far past
    the oldest unacked fragment. Should save unnecessary scans for large block
    sizes.

    --------------------

    Optimize the block send and receive to not require a data copy or allocation
    for each fragment data block, use pointers and directly serialize in/out of
    block data instead.

    --------------------

    Could save a bit of memory by switching the received fragment data to a bitfield

    We only need one bit per-fragment, "has it been received?"

    --------------------

    I don't like the exception throw on packet receive. This is sloppy!

    These are not exceptional conditions. These *can* and do happen under
    real usage, all it requires is some latency or out of order packets.

    Using an exception (slow path) for such things is *WRONG*

    return false from process data to indicate the packet should be discarded instead!

    eg. ProcessData should return false if it wants a packet discard.

    ---------------------

    What is next?

    1) Start doing performance analysis (CPU, memory etc.)

    2) Investigate using a custom allocator. Potentially ditch STL usage at this point.

    3) Consider cost of shared_ptr. Is it slow? Where should I use it? Where should I not?

    4) Integrate the oodle library. Provide an #if USE_OODLE 1 type thing and hook it up
       for compression. Try it out in the stress test and see how it generates dictionaries
       and how much compression it gets post-dictionary and so on. Do not check in the oodle
       libs, but do check in the interface and source code that uses it.

    5) Implement encryption via key, plus hash to detect tampering (unified). Optional feature.

    6) Implement an unreliable channel (messages), 
       eg. queue up unreliable messages to send and discard any that don't fit in the packet.
       Bonus: Provide an optional functor to sort the unreliable messages in order of importance.

    7) Implement an atomic queue on top of the client and server interface for sending
       and receiving user packets. This interface should allow running the actual serialization
       and packet reading entirely on a separate thread. Do it here where it is most natural,
       to avoid overcomplicating the interface/connection code.

    ------------------

    I think the DNS lookup integration in the net interface is bad.

    It complicates the net interface, and derived classes (eg. network simulator)
    now don't fully implement the base class.

    I think DNS resolve actually belongs inside client/server classes
    as part of the client -> server connect state machine.

    ----------------
