DONE:

    Configuration of world should be shared across all demos, eg. standardize it.

    Added way to reload demo. This recreates the demo structure from scratch, as well as reloads all assets.

    Cubes internal should take description for how many simulations there should be,
    and how many views there should be.

    For example, there could be 4 simulations but only one view.

    Code should be able to pipe arbitrarily from one simulation and render to a defined view.

    At the moment, what I need is either one simulation and one view, or two simulations and two views.

    BUT... soon for interpolation and snapshot, I'll need one simulation and two views, and a
    kickass interpolated/extrapolated thing to feed the view.

    So I should structure such that this is possible.

    Interface to create n simulations

    Interface to create n views

    Generalize code such that simulation and views are kept separate

    Make sure generalized code is working with existing singleplayer cubes demo before going further.

TODO:

    Code seems to crash if I don't have a demo loaded, eg. black screen.

    Shouldn't it be clearing the screen to white?

    What is going on?

    -------------------------------------------

    We need something to pass into the update that describes the update to be performed,

    eg. which simulations to update. Which players are joined per-simulation.
    Whether local input should be applied to that simulation, and to which player.

    There also needs to be a mapping from view to simulation, eg. -1 means, no mapping
    while 0 means, view gets output from simulation 0 and draws that.

    The view focus of each player should also be specified per-view, eg. view 2 may be
    viewing object 5. etc...

    This allows insertion such that cubes can be rendered entirely without simulation

    This is super important for the snapshot interpolation demo.

    --------------------------------------------

    Interface to render view to only a portion of the screen vs. whole

    -------------------------------------------

    Interface to render splitscreen divider inside render interface (eg. dashed vertical line)

    -------------------------------------------

    Implement lockstep demo.

    First just transmit the same input to both sides and see that they play out correctly.

    Next, actually construct a packet protocol and delay the packets a certain amount (on the network,
    and when received before being played back)

    Goal is to implement proper playout delay buffer.

    Just fucking *do this* you pussy. This needs to be done. Actually implement it.

    -------------------------------------------

    Snapshots demo

    -------------------------------------------

    Stateful demo

    -------------------------------------------

    Write rest of article series

    -------------------------------------------

    Polish cube demo implementation as much as possible

    Port to windows and make sure it runs on Win64

    Release source code for singleplayer, lockstep, snapshot and stateful demos.

    -------------------------------------------

    Prepare GDC slides from article series

    -------------------------------------------






    --------------------------------------------------------------

    Explore various different interpolation strategies to use for 2D linear motion.

    Share this demo with Nathan (pro-bono) and try to get some involvement back with their project.

    --------------------------------------------------------------

    Return to PBR rendering

    --------------------------------------------------------------

    Convert DDS loading to use nvImage to load HDR uffizi cubemap.

    Work on exposure and get the scene looking good with HDR, may need to bump up direct light intensity?

    ----------------------------------

    Get roughness working with this HDR cubemap, eg. use roughness to index the mip chain.

    Look into a normalized BRDF function that accepts roughness, eg. microfacet model.

    ----------------------------------

    Get fresnel working so some reflection is visible even on the diffuse stone and more 
    reflection is visible at grazing angles (quite important for realistic go stone visuals)

    ----------------------------------

    Reread Seb Legarde stuff again start to finish.

    http://seblagarde.wordpress.com/2011/08/17/hello-world/

    Dig in a bit deeper into the source material (especially Naty's siggraph talks)
    and understand the math and physical reasoning behind it.

    Start here:

    http://renderwonk.com/publications/s2010-shading-course/hoffman/s2010_physically_based_shading_hoffman_a_notes.pdf

    ----------------------------------

    Continue studying trip through the graphics pipeline.

    ----------------------------------

    Identify areas where my math is weak and work to study those parts.

    Khan Academy? Probably the best bet to start.

    Get a desk so I can study.

    ----------------------------------

    Get go board rendering working

    ----------------------------------

    Render skybox and then in-game, render a cubemap from the center of a stone (size 35?)

    Make sure this cubemap is captured in HDR, eg. pre-tonemapping.

    This cubemap can then be input into CubeMapGen or cmft to get a correct radiance 
    and irradiance cubemap including the go board in the scene, eg. reflected color of the wood.

    ----------------------------------

    Research raytracing signed distance fields for shadows

    ----------------------------------
