DONE:

TODO:

    Add code to gather n messages to include in packet serialize write

    Add code to ignore messages that have already been sent within "send rate" of current time.

    Don't send messages that are > send queue size / 2 ahead of oldest message in send queue.

    Ignore message packing. Assume that max # of messages in packet will not exceed max packet size.

    Add sliding window for packets "m_sentPackets" with a vector of size max messages per packet.

    Add code to process acks and walk the m_sentPackets, if not already acked, mark that packet acked, 
    and then walk over all messages in send queue and remove them from the send queue.

    Add logs to verify this is working properly on the send side.
    
    --------------

    Now implement the receive side.

    When a packet comes in add the messages in it to the receive queue.

    If any message cannot be inserted into the receive queue, discard the packet.

    Implement the code to walk the receive queue and receive most recent message,
    eg. if the message at sequence m_receiveId is valid then pop it, and allow
    repeat until you hit a message entry that is invalid.

    Logic should be pretty easy.

    --------------
    
    Now implement code to measure events and determine if they can fit into packet.

    Should this measurement be done at the point of constructing the packet data? (probably)

    How to ensure that this measurement is done only once?

    Don't just append one stream to another, as it throws off the journal check.

    ------------------

    Next implement fragmentation and reassembly for large blocks.

    Important: Think about large packets with fragmentation
    If a large packet is coming up ahead, make sure previous
    non-fragmented packets before it have all been sent, eg.
    only commit to sending a large fragmented block once 
    the previous blocks have been sent.

    Next: After a fragmented block. Basically, assume the fragmented
    block will take a long time. There is probably not a lot of benefit
    sending blocks *after* the fragmented block in anticipation of the
    block being sent. Unless the fragmented block is small (eg. only
    a few fragments). If it is a large, large chunk -- then it's
    best to stop and wait for that chunk to finish serializing through
    in slices.

    Important: Slice size should be fixed, and basically be as much
    data as you can fit in the channel configuration. Don't send #
    of bytes with each slice. You know the size from config.

    At end, make sure not to trash extra data, but do send extra 0's
    in the packet, to avoid special cases.

    ---------------------

PROTOCOL AND SERVER:

    Cap'n Proto looks a bit overengineered (eg. second systems effect)

    MessagePack looks a bit smaller and tight to me, but probably less efficient
    over the wire and in terms of packing time.

    Are protocol buffers worth integrating?

    Google snappy looks like a nice candidate for message compression

    Is there a nice library for message encryption between servers over UDP?
    (eg. a shared secret is fine, server code is not distributed)

    Nettle library looks OK. Does google have a library that they use?

    On write:

        serialize write -> compress -> encrypt -> sign -> send

    On read:

        recv -> verify signature -> decrypt -> serialize read

    If I have my own reliable ordered block channel, I can then derive
    specific channels from that, eg. JSONChannel, CapnProtoChannel,
    MsgPackChannel, ThriftChannel and so on... should be easy to add
    additional libraries and try them out. Try them all! :D

OPTIMIZATION:

    Implement bit packer first.

    Next try to implement range encoder.

    Study range encoder. How does it work? Can the decryption be done in place as per bitpacker?

    Send and receive queues should be lockless threadsafe

    Separate send and receive threads for NetworkInterface

    Some ninja must be done to make it easy for the channels to work
    with serialization being done on a separate thread. Ouch?

    Investigate different methods for sending and receiving UDP packets,
    eg. completion ports on Win32, whatever method is fastest on linux etc.

    Run throughput tests with linux hosts. Test CPU usage etc.
