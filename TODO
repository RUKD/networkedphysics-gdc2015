DONE:

    Now work out how we can apply this to client/server
    to only allow connection packets through with the 
    expected client and server guids.

    I think there should be a client server context.

    This should be a basic struct, it should contain the client and server guids
    and a bool indicating whether or not a connection has been established.

    Add client/server context: ClientServerContext.h

    Add a method to network interface to set context for serialization.

    Made get/set context const safe.

    Inside BSDSocket take the context saved and apply to read and write
    stream when serializing a packet.

    IDEA: It might be nicer to set an array of contexts on the stream
    vs. setting each context individually on the stream.

    This means the stream itself doesn't really "own" the array
    of contexts, it could be owned by the client/server and updated
    behind the back of the network interface.

    I think this is a much more flexible setup.

    This would allow users to modify via client/server interface
    the set of contexts on the fly, which is needed, vs. having to
    call out to the network interface, which calls out to the stream
    and so on...

TODO:
    
    Adjust the context system to work this way.

    Update the test_stream_context function to do this.

    -------------------------

    Put the context array void*[MaxContexts] inside the client and server.

    Set the first context (0) to point to the client server context.

    Move the client/server guids back into the connection packet.

    Make the connection packet require context[0] (ClientServerContext)

    If a connection is not established, discard the connection packet (how? set overflow?)

    If the client or server guids don't match, discard the connection packet.

    Add hooks to set the context when connection is established, and clear it
    when connection is torn down, on client and server side.

    Make sure all unit tests and soaks still pass.

    -------------------------

    In situations where measure streams are used, channels need a way
    to construct a stream with the appropriate contexts set on it.

    How can this be done?

    Seems like channels need access to a function that returns the 
    appropriate const void ** context pointer.

    -------------------------

    Might be a good idea to put the client/server context in the last
    slot, so the user can set slot 0. otherwise going to be annoying
    explaining to users why they have to start with slot 1 or higher.

    -------------------------

    In unit tests, add some sort of context message, eg. a message
    that would only function if a context is properly set on the 
    client/server.

    Subclass client/server for tests, and in the subclass implement
    something like OnConnected, OnDisconnected or whatever, such that
    context is setup on both client/server.

    -------------------------

    Implement something for the client/server test where the first
    256 bytes of the client/server data is reserved for a context
    struct.

    Subclass the client/server and set the context to the server
    data once connection is established (on both client/server),
    as well as clear the context when disconnected.

    Make sure that the test context message cannot serialize
    without having this context available. Just simple min/max
    for quantities in the test context message.

    Randomize the min/max context for each server, such that they
    are wildly different for each server, and completely incompatible
    eg. serialization will fail/assert if desynced.

    Verify that the soak client/server is able to function with
    repeated connect/disconnect and exchange of server data driving
    the context needed for test context messages.

    -------------------------









    ^------------ AT THIS POINT READY FOR SEND TABLES











    ------------------------

    Integrate LZ compressor for compressing large blocks, and for compressing
    initial block sent down to client.

    Ideally, LZ4 could be something enabled via config that is used, if it exists
    this way it is up to the user of the library to ensure they have LZ4 installed.

    I don't want to manage the LZ4 library includes/libs inside my library,
    if I can avoid it.

    It might be a good idea to see if LZ4 can compress typical packets sent as well,
    for example, put a bit in the header indicating that the packet is compressed,
    if LZ4 is enabled, and then decode the packet via LZ4.

    This would have to live at the network interface level, presumably.

    Potentially set a minimum packet size or block size for LZ compression,
    and even then, check if the compressed packet/block is larger than uncompressed
    and send uncompressed instead.

    Per-packet or block (large block), we would need a bit indicating if compressed.

    ------------------------

    Implement fragmentation and reassembly for large packets, do this
    at the connection level once we have large snapshots, this would
    probably be a good idea to have -- set MTU to 1200 bytes.

    Keep it simple. A packet is received when all its fragments
    have been received. If any of the fragments are dropped,
    then the packet is dropped.

    I propose a simple header, eg. a packet type for fragment packet
    with a header x/y fragments and the sequence number of the *unacked*
    packet.

    Then the complexity becomes:

    a) writing the fragments, and not sending them out too rapidly
    b) on the receive side collating the fragments and reassembling them.

    ------------------------

    Where does fragmentation and reassembly live?

    Ideally, I would like for it to be in the connection layer
    or at least somewhere that it doesn't need to be implemented
    from scratch with each different network interface implementation.

    Is this possible?

    Maybe it should just be at the interface level.

    ------------------------





    ------------------------

    Actually implement a client/server setup and host the server in the cloud.

    Provide build steps using chef/knife or whatever to easily deploy this server.

    How any server instances can I have per-core?

    ------------------------






    *** SEND TABLES ***

    ---------------

    Implement send table concept. Implement delta encoding tables etc.

    Use the server data to communicate this table down to the client.

    ---------------