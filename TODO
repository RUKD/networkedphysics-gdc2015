DONE:

TODO:

    Consider renaming channel data to packet data

    eg. ReliableBlockPacketData

    Generalize the reliable block packet data such that it can
    contain multiple reliable blocks, eg. split back out into
    ReliableBlockData

    Reliable block packet data should also know the maximum
    bytes per-block that can be serialized per-packet, before
    they get split up into fragments.

    This should basically be the block fragment size, which should
    be the channel configured # of bytes minus any overhead.

    ------------------

    Next implement multiple blocks being included in the same packet.

    Add some basic configuration, eg. maximum bytes to write per-packet
    for the reliable channel, resend rate per-block, eg. 4 times a second

    The idea here is that if multiple blocks are queued up, and they
    can both fit into the stashed data then they should both be
    included in the packet.

    Now we need a send queue sliding window with time last sent
    per-block, not just a simple send queue.

    ---------------------

    Next implement fragmentation and reassembly for large blocks.

    Important: Think about large packets with fragmentation
    If a large packet is coming up ahead, make sure previous
    non-fragmented packets before it have all been sent, eg.
    only commit to sending a large fragmented block once 
    the previous blocks have been sent.

    Next: After a fragmented block. Basically, assume the fragmented
    block will take a long time. There is probably not a lot of benefit
    sending blocks *after* the fragmented block in anticipation of the
    block being sent. Unless the fragmented block is small (eg. only
    a few fragments). If it is a large, large chunk -- then it's
    best to stop and wait for that chunk to finish serializing through
    in slices.

    Important: Slice size should be fixed, and basically be as much
    data as you can fit in the channel configuration. Don't send #
    of bytes with each slice. You know the size from config.

    At end, make sure not to trash extra data, but do send extra 0's
    in the packet, to avoid special cases.

    ---------------------

PROTOCOL AND SERVER:

    Cap'n Proto looks a bit overengineered (eg. second systems effect)

    MessagePack looks a bit smaller and tight to me, but probably less efficient
    over the wire and in terms of packing time.

    Are protocol buffers worth integrating?

    Google snappy looks like a nice candidate for message compression

    Is there a nice library for message encryption between servers over UDP?
    (eg. a shared secret is fine, server code is not distributed)

    Nettle library looks OK. Does google have a library that they use?

    On write:

        serialize write -> compress -> encrypt -> sign -> send

    On read:

        recv -> verify signature -> decrypt -> serialize read

    If I have my own reliable ordered block channel, I can then derive
    specific channels from that, eg. JSONChannel, CapnProtoChannel,
    MsgPackChannel, ThriftChannel and so on... should be easy to add
    additional libraries and try them out. Try them all! :D

OPTIMIZATION:

    Implement bit packer first.

    Next try to implement range encoder.

    Study range encoder. How does it work? Can the decryption be done in place as per bitpacker?

    Send and receive queues should be lockless threadsafe

    Separate send and receive threads for NetworkInterface

    Some ninja must be done to make it easy for the channels to work
    with serialization being done on a separate thread. Ouch?

    Investigate different methods for sending and receiving UDP packets,
    eg. completion ports on Win32, whatever method is fastest on linux etc.

    Run throughput tests with linux hosts. Test CPU usage etc.
