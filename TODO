DONE:

TODO:

    -----------------------------

    It seems a bit of a slam dunk than channel structure should be context[0]
    and client server context should be context[1].

    This has a lot of benefits, including simplification of packet factory.

    Make it so.

    -----------------------------

    There should be context enums, like CONTEXT_CHANNEL_STRUCTURE
    and CONTEXT_CLIENT_SERVER

    There should also be CONTEXT_USER

    So the user knows where their user contexts must start from,
    eg. CONTEXT_USER, CONTEXT_USER + 1 and so on.

    -----------------------------







    -------------------------

    In situations where measure streams are used, channels need a way
    to construct a stream with the appropriate contexts set on it.

    How can this be done?

    Seems like channels need access to a function that returns the 
    appropriate const void ** context pointer to set on the measure stream.

    -------------------------

    In unit tests, add some sort of context message, eg. a message
    that would only function if a context is properly set on the 
    client/server.

    Subclass client/server for tests, and in the subclass implement
    something like OnConnected, OnDisconnected or whatever, such that
    context is setup on both client/server.

    -------------------------

    Implement something for the client/server test where the first
    256 bytes of the client/server data is reserved for a context
    struct.

    Subclass the client/server and set the context to the server
    data once connection is established (on both client/server),
    as well as clear the context when disconnected.

    Make sure that the test context message cannot serialize
    without having this context available. Just simple min/max
    for quantities in the test context message.

    Randomize the min/max context for each server, such that they
    are wildly different for each server, and completely incompatible
    eg. serialization will fail/assert if desynced.

    Verify that the soak client/server is able to function with
    repeated connect/disconnect and exchange of server data driving
    the context needed for test context messages.

    -------------------------









    ------------------------

    Integrate LZ compressor for compressing large blocks, and for compressing
    initial block sent down to client.

    Ideally, LZ4 could be something enabled via config that is used, if it exists
    this way it is up to the user of the library to ensure they have LZ4 installed.

    I don't want to manage the LZ4 library includes/libs inside my library,
    if I can avoid it.

    It might be a good idea to see if LZ4 can compress typical packets sent as well,
    for example, put a bit in the header indicating that the packet is compressed,
    if LZ4 is enabled, and then decode the packet via LZ4.

    This would have to live at the network interface level, presumably.

    Potentially set a minimum packet size or block size for LZ compression,
    and even then, check if the compressed packet/block is larger than uncompressed
    and send uncompressed instead.

    Per-packet or block (large block), we would need a bit indicating if compressed.

    ------------------------

    Implement fragmentation and reassembly for large packets, do this
    at the connection level once we have large snapshots, this would
    probably be a good idea to have -- set MTU to 1200 bytes.

    Keep it simple. A packet is received when all its fragments
    have been received. If any of the fragments are dropped,
    then the packet is dropped.

    I propose a simple header, eg. a packet type for fragment packet
    with a header x/y fragments and the sequence number of the *unacked*
    packet.

    Then the complexity becomes:

    a) writing the fragments, and not sending them out too rapidly
    b) on the receive side collating the fragments and reassembling them.

    ------------------------

    Where does fragmentation and reassembly live?

    Ideally, I would like for it to be in the connection layer
    or at least somewhere that it doesn't need to be implemented
    from scratch with each different network interface implementation.

    Is this possible?

    Maybe it should just be at the interface level.

    ------------------------





    ------------------------

    Actually implement a client/server setup and host the server in the cloud.

    Provide build steps using chef/knife or whatever to easily deploy this server.

    How many server instances can I have per-core?

    ------------------------






    *** SEND TABLES ***

    ---------------

    Implement send table concept. Implement delta encoding tables etc.

    Use the server data to communicate this table down to the client.

    ---------------
